apiVersion: v1
kind: Namespace
metadata:
  name: gpu-test

---
## Define a single ResourceClaim for the shared GPU (created once)
## This ResourceClaim is created up front and then referenced by multiple pods below.
apiVersion: resource.k8s.io/v1
kind: ResourceClaim
metadata:
  namespace: gpu-test
  name: shared-gpu-claim # A distinct name for the shared claim
spec:
  devices:
    requests:
    - name: gpu
      exactly:
        deviceClassName: gpu.amd.com
        allocationMode: ExactCount
        count: 1

---
apiVersion: v1
kind: Pod
metadata:
  namespace: gpu-test
  name: pod1 # First pod to use the shared GPU
  labels:
    app: pod-shared-gpu
spec:
  containers:
  - name: ctr0
    image: docker.io/rocm/pytorch:latest # Or a specific ROCm version, e.g., rocm/pytorch:rocm-6.4.2-ubuntu-22.04
    command: ["bash", "-c"]
    # Simplified args: run rocm-smi, then sleep
    args: ["echo '--- Pod 1 ---'; /opt/rocm/bin/rocm-smi --showid --showuse --csv; echo 'Pod 1 complete. Sleeping...'; sleep infinity"]
    resources:
      claims:
      - name: gpu # This name must match the name in the `resourceClaims` list below
  resourceClaims:
  - name: gpu
    # 2. Reference the *explicitly created* ResourceClaim, not a template
    resourceClaimName: shared-gpu-claim

---
apiVersion: v1
kind: Pod
metadata:
  namespace: gpu-test
  name: pod2 # Second pod to use the SAME shared GPU
  labels:
    app: pod-shared-gpu
spec:
  containers:
  - name: ctr0
    image: docker.io/rocm/pytorch:latest # Or a specific ROCm version
    command: ["bash", "-c"]
    # Simplified args: run rocm-smi, then sleep
    args: ["echo '--- Pod 2 ---'; /opt/rocm/bin/rocm-smi --showid --showuse --csv; echo 'Pod 2 complete. Sleeping...'; sleep infinity"]
    resources:
      claims:
      - name: gpu
  resourceClaims:
  - name: gpu
    # 2. Reference the *same explicit* ResourceClaim
    resourceClaimName: shared-gpu-claim
